\documentclass[11pt]{article}

% ------------------------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% ------------------------------------------------------------------------------

\usepackage[margin=.8in,top=1.1in,bottom=1.1in]{geometry} % page layout
\usepackage{amsmath,amsthm,amssymb,amsfonts} % math things
\usepackage{graphicx} % include graphics
\usepackage{fancyhdr} % header customization
\usepackage{titlesec} % help with section naming
\usepackage{listings}
\usepackage[final]{pdfpages}

% naming sections
\titleformat{\section}{\bf}{Problem \thesection}{0.5em}{}
\newcommand{\exercise}{\section{}}

% headers
\pagestyle{fancy}
\fancyhf{} % clear all
\fancyhead[L]{\sffamily\small Machine Learning 1 --- Homework}
\fancyhead[R]{\sffamily\small Page \thepage}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.2pt}
\markright{\hrulefill\quad}

\newcommand{\hwhead}[4]{
\begin{center}
\sffamily\large\bfseries Machine Learning Worksheet #1
\vspace{2mm}
\normalfont

#2\\
#3\\
\texttt{#4}
\end{center}
\vspace{6mm} \hrule \vspace{4mm}
}

% ------------------------------------------------------------------------------
% Start here -- Fill in your name, imat and email
% (and the same for who you worked with)
% You are allowed to work in groups of 2 (or 3 if there is no way around it)
% However, you each must submit individually - (it may be same file)
% ------------------------------------------------------------------------------

\newcommand{\names}{Tomas Ladek} %
\newcommand{\imats}{3602673} %
\newcommand{\emails}{tom.ladek@tum.de} %

\begin{document}

% ------------------------------------------------------------------------------
% Change xx (and only xx) to the current sheet number
% ------------------------------------------------------------------------------
\hwhead{2}{\names}{\imats}{\emails}

% ------------------------------------------------------------------------------
% Fill in your solutions
% ------------------------------------------------------------------------------

\exercise
After parsing the data that was given in a csv file and making up an efficient data structure (matrix), the Gini index of the root node ($C = \{0, 1, 2\}$) was calculated:
\begin{align*}
	i_G(t) &= 1 - (\dfrac{5}{15})^2 - (\dfrac{6}{15})^2 - (\dfrac{4}{15})^2
\end{align*}
Then in 0.1 steps from -0.6 to +10.0 (limits determined by data inspection), the Gini index of all possible left/right splits of the root node was calculated, for all features $x_{i,1}...x_{i,3}$. The maximum was a difference in Gini indices of $\approx0.3615$ for the first feature ($x_{i,1}$) for a split at the value 4.5\footnote{Due to the chosen calculation procedure, the split values take the maximum possible value between two different splits, instead of the average.}. The formula used for calculating the difference was

\begin{align*}
	\Delta i_G(t) (x_{i,1} \le s, t) &= i_G(t) - \dfrac{ \#classes\ in\ left\ tree}{\#classes\ in\ current\ data\ set}i_G(t_L) - \dfrac{ \#classes\ in\ right\ tree}{\#classes\ in\ current\ data\ set}i_G(t_R)
\end{align*}

with $i_G$ being the Gini indices of the current node, the left tree and the right tree respectively.\\

Splitting the root node at $x_{i,1} = 4.5$ yielded a left tree (values less than or equal to the split value) consisting of a pure node (class distribution of 100\% for class '1', Gini index 0) and a right tree combining the remaining classes '0' and '2', Gini index 0.4938. No further splits in the left tree were needed.\\

 Once again performing a maximalization on the Gini index differences for every possible split of every feature in 0.1 steps yielded feature $x_{i,1}$ at 7.4 as the best split. The result was a left sub-tree with class distribution '2': $\dfrac{2}{3}$; '0': $\dfrac{1}{3}$ and a right sub-tree with a pure distribution of class '0'. The corresponding Gini indices were 0.4444 and 0 respectively.\\
 
 As the maximum requested depth was reached, no further splitting was considered. The (raw) python code can be provided on request.
 
\exercise
By using the tree that was constructed and explained above, the vector $\mathbf{x}_a$ is classified as '1' (following the left sub-tree, since $\mathbf{x}_{a,1} \le 4.5$). Being a pure leaf node, $p(c=1|\mathbf{x}_a,T) = 1$.\\

Vector $\mathbf{x}_b$ follows the right sub-tree ($\mathbf{x}_{b,1} > 4.5$) and ends up in its left leaf (($\mathbf{x}_{b,1} \le 7.4$)). The corresponding classification is '2', because '2' is the majority class in that node. The probability of a correct classification is $p(c=2|\mathbf{x}_b,T) = \dfrac{2}{3}$, due to the class distribution of that node.

\exercise
\includepdf[pages=-]{02_homework_knn.pdf}

\exercise
Euclidean distance: $d = \sqrt{\sum_i(u_i - v_i)^2}$\\
Distances for $\mathbf{x}_a$:\\
$d_A=2.76 \quad d_B = 3.78 \quad d_C=2.18 \quad d_D=5.97 \quad d_E = 3.22 \quad d_F = 3.97 \quad d_G = 2.93 \quad d_H = 2.83 \\
d_I=0.67 \quad d_J=3.6 \quad d_K=2.84 \quad d_L=5.3 \quad d_M = 3.16 \quad d_N = 4.26 \quad d_O = 2.47$\\
$\Rightarrow$ 3-nearest neighbors are $I, C, O$ corresponding to classes ('0', '2' and '1' respectively). Therefore:\\
$p(z=0|x, 3) = \dfrac{1}{3} \cdot 1\\
p(z=1|x, 3) = \dfrac{1}{3} \cdot 1\\
p(z=2|x, 3) = \dfrac{1}{3} \cdot 1$\\

Distances for $\mathbf{x}_b$:\\
$d_A=3.26 \quad d_B = 2.73 \quad d_C=2.12 \quad d_D=3.84 \quad d_E = 1.17 \quad d_F = 3.93 \quad d_G = 4.3 \quad d_H = 4.86 \\
d_I=1.75 \quad d_J=5.7 \quad d_K=3.15 \quad d_L=3.77 \quad d_M = 5.32 \quad d_N = 6.45 \quad d_O = 4.56$\\
$\Rightarrow$ 3-nearest neighbors are $E, I, C$ corresponding to classes ('2', '0' and '2' respectively). Therefore:\\
$p(z=0|x, 3) = \dfrac{1}{3} \cdot 1 = \dfrac{1}{3}\\
p(z=2|x, 3) = \dfrac{1}{3} \cdot 2 = \dfrac{2}{3}$

\exercise
$y = \dfrac{1}{\sum_{i\in N_k(x)}\dfrac{1}{d(x,x_i)}} \sum_{i\in N_k(x)}\dfrac{1}{d(x,x_i)} z_i$\\

For $\mathbf{x}_a$:
$y=0.56$\\
For $\mathbf{x}_b$:
$y=1.398$


\end{document}