\documentclass[11pt]{article}

% ------------------------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% ------------------------------------------------------------------------------

\usepackage[margin=.8in,top=1.1in,bottom=1.1in]{geometry} % page layout
\usepackage{amsmath,amsthm,amssymb,amsfonts} % math things
\usepackage{graphicx} % include graphics
\usepackage{fancyhdr} % header customization
\usepackage{titlesec} % help with section naming
\usepackage{listings}
\usepackage[final]{pdfpages}

% naming sections
\titleformat{\section}{\bf}{Problem \thesection}{0.5em}{}
\newcommand{\exercise}{\section{}}

% headers
\pagestyle{fancy}
\fancyhf{} % clear all
\fancyhead[L]{\sffamily\small Machine Learning 1 --- Homework}
\fancyhead[R]{\sffamily\small Page \thepage}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.2pt}
\markright{\hrulefill\quad}

\newcommand{\hwhead}[4]{
\begin{center}
\sffamily\large\bfseries Machine Learning Worksheet #1
\vspace{2mm}
\normalfont

#2\\
#3\\
\texttt{#4}
\end{center}
\vspace{6mm} \hrule \vspace{4mm}
}

% ------------------------------------------------------------------------------
% Start here -- Fill in your name, imat and email
% (and the same for who you worked with)
% You are allowed to work in groups of 2 (or 3 if there is no way around it)
% However, you each must submit individually - (it may be same file)
% ------------------------------------------------------------------------------

\newcommand{\names}{Tomas Ladek, Michael Kratzer} %
\newcommand{\imats}{3602673, 3612903} %
\newcommand{\emails}{tom.ladek@tum.de, mkratzer@mytum.de} %

\begin{document}

% ------------------------------------------------------------------------------
% Change xx (and only xx) to the current sheet number
% ------------------------------------------------------------------------------
\hwhead{11}{\names}{\imats}{\emails}

% ------------------------------------------------------------------------------
% Fill in your solutions
% ------------------------------------------------------------------------------

\exercise
Consider a Gaussian Mixture Model that describes the data points $\boldsymbol{x}$
\begin{align*}
	p (x | \theta) = \sum_{k = 0}^{K} \pi_k \mathcal N(x | \mu_k, \sigma^2 \boldsymbol{I})
\end{align*}
with some $\sigma \in \mathbb{R}$. Let us define $\pi_k = \dfrac{|C_k|}{N}$ with $|C_k|$ being the number of data point belonging to a cluster $k$ and $N$ the total number of data points.\\

\noindent Since we cannot easily optimize
\begin{align*}
	\arg \max_{\theta} \ln p(\mathcal{D}|\theta) = \sum_{n=1}^{N} \ln \sum_{k=0}^{K} \dfrac{|C_k|}{N} \mathcal{N}(x_n | \mu_k, \sigma^2 \boldsymbol{I})
\end{align*}
we use the EM algorithm, which consists of
\begin{enumerate}
	\item Fixing the parameters of some posterior distribution and calculating responsibilities for a data point $x$.
	\item Fixing responsibilities for a data point $x$ and optimizing the parameters of the underlying distribution.
\end{enumerate}
Because the Euclidean metric puts equidistant points on a sphere (in 3D; on a circle in 2D, etc.), one can easily see how this metric can be implemented by employing a spherical Gaussian, i.e. one with a diagonal covariance matrix. The first step in the EM algorithm now is choosing some Gaussian means $\mu_k$ and calculating responsibilities by evaluating the Gaussian at $||x_n - \mu_k||_2$ for every data point $x_n$ - corresponds to the step ''Calculate clusters''. The second step of finding optimal parameters for the Gaussians then corresponds to ''recalibrating the cluster means'' with $\mu_k \leftarrow \dfrac{1}{|C_k|} \sum_{x \in C_k} x$.\\

\noindent More formally:

%In EM, we are doing alternate coordinate ascent on $\mathcal{L}_{ELBO}(q, \theta)$ for some posterior distribution $q(z)$, i.e. two steps:
%\begin{enumerate}
%	\item Optimization w.r.t. $q$
%	\begin{align*}
%		\arg \max_q \mathcal{L}_{ELBO}(q, \theta) &= \arg \max_q \mathbb{E}_{q(z)}[\ln p(x, z | \theta)] + \text{H}(q)
%	\end{align*}
%	\item Optimization w.r.t. parameters $\theta$
%	\begin{align*}
%	\arg \max_{\theta} \mathcal{L}_{ELBO}(q, \theta) &= \arg \max_{\theta} \mathbb{E}_{q(z)}[\ln p(x, z | \theta)] + \text{H}(q)\\
%	&= \arg \max_{\theta} \mathbb{E}_{q(z)}[\ln p(x, z | \theta)]
%	\end{align*}
%\end{enumerate}


\end{document}