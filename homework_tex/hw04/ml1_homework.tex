\documentclass[11pt]{article}

% ------------------------------------------------------------------------------
% This is all preamble stuff that you don't have to worry about.
% Head down to where it says "Start here"
% ------------------------------------------------------------------------------

\usepackage[margin=.8in,top=1.1in,bottom=1.1in]{geometry} % page layout
\usepackage{amsmath,amsthm,amssymb,amsfonts} % math things
\usepackage{graphicx} % include graphics
\usepackage{fancyhdr} % header customization
\usepackage{titlesec} % help with section naming
\usepackage{listings}
\usepackage[final]{pdfpages}

% naming sections
\titleformat{\section}{\bf}{Problem \thesection}{0.5em}{}
\newcommand{\exercise}{\section{}}

% headers
\pagestyle{fancy}
\fancyhf{} % clear all
\fancyhead[L]{\sffamily\small Machine Learning 1 --- Homework}
\fancyhead[R]{\sffamily\small Page \thepage}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.2pt}
\markright{\hrulefill\quad}

\newcommand{\hwhead}[4]{
\begin{center}
\sffamily\large\bfseries Machine Learning Worksheet #1
\vspace{2mm}
\normalfont

#2\\
#3\\
\texttt{#4}
\end{center}
\vspace{6mm} \hrule \vspace{4mm}
}

% ------------------------------------------------------------------------------
% Start here -- Fill in your name, imat and email
% (and the same for who you worked with)
% You are allowed to work in groups of 2 (or 3 if there is no way around it)
% However, you each must submit individually - (it may be same file)
% ------------------------------------------------------------------------------

\newcommand{\names}{Tomas Ladek, Michael Kratzer} %
\newcommand{\imats}{3602673, 3612903} %
\newcommand{\emails}{tom.ladek@tum.de, mkratzer@mytum.de} %

\begin{document}

% ------------------------------------------------------------------------------
% Change xx (and only xx) to the current sheet number
% ------------------------------------------------------------------------------
\hwhead{4}{\names}{\imats}{\emails}

% ------------------------------------------------------------------------------
% Fill in your solutions
% ------------------------------------------------------------------------------

\exercise
The Inverse of a diagonal atrix is just a diagonal matrix with each of the elements inverted.
\begin{align}
	\Lambda^{-1} = 
	\begin{pmatrix}
	\frac{1}{\lambda_1} & \dots & 0 \\
	\vdots & \ddots & \vdots \\
	0 & \dots & \frac{1}{\lambda_d}
	\end{pmatrix}
	,
	U = 
	\begin{pmatrix}
	u_{1,1} & \dots & u_{1,d} \\
	\vdots & \ddots & \vdots \\
	u_{d,1} & \dots & u_{d,d}
	\end{pmatrix}
\end{align}
Just multiplying $U\Lambda U^{T}$ results in what should be proven.

\begin{align}
	U\Lambda U^{T} &= 
		\begin{pmatrix}
		u_{1,1} & \dots & u_{1,d} \\
		\vdots & \ddots & \vdots \\
		u_{d,1} & \dots & u_{d,d}
		\end{pmatrix}
		\begin{pmatrix}
		\frac{1}{\lambda_1} & \dots & 0 \\
		\vdots & \ddots & \vdots \\
		0 & \dots & \frac{1}{\lambda_d}
		\end{pmatrix}
		\begin{pmatrix}
		u_{1,1} & \dots & u_{d,1} \\
		\vdots & \ddots & \vdots \\
		u_{1,d} & \dots & u_{d,d}
		\end{pmatrix} 
		\\
		&= 
		\begin{pmatrix}
		\frac{u_{1,1}}{\lambda_1} & \dots & \frac{u_{1,d}}{\lambda_d} \\
		\vdots & \ddots & \vdots \\
		\frac{u_{d,1}}{\lambda_1} & \dots & \frac{u_{d,d}}{\lambda_d}
		\end{pmatrix}
		\begin{pmatrix}
		u_{1,1} & \dots & u_{d,1} \\
		\vdots & \ddots & \vdots \\
		u_{1,d} & \dots & u_{d,d}
		\end{pmatrix}
		\\
		&=
		\begin{pmatrix}
		\frac{u_{1,1}u_{1,1}}{\lambda_1}+\dots+\frac{u_{1,d}u_{1,d}}{\lambda_d} & \dots & \frac{u_{1,1}u_{d,1}}{\lambda_1} + \dots + \frac{u_{1,d}u_{d,d}}{\lambda_d} \\
		\vdots & \ddots & \vdots \\
		\frac{u_{d,1}u_{1,1}}{\lambda_1} + \dots + \frac{u_{1,d}u_{d,d}}{\lambda_d} & \dots & \frac{u_{d,1}u_{d,1}}{\lambda_1} + \dots + \frac{u_{d,d}u_{d,d}}{\lambda_d}
		\end{pmatrix}
		\\
		&=
		\frac{1}{\lambda_1}
		\begin{pmatrix}
		u_{1,1}u_{1,1} & \dots & u_{1,1}u_{d,1} \\
		\vdots & \ddots & \vdots \\
		u_{d,1}u_{1,1} & \dots & u_{d,1}u_{d,1}
		\end{pmatrix}
		+ \dots +
		\frac{1}{\lambda_d}
		\begin{pmatrix}
		u_{1,d}u_{1,d} & \dots & u_{1,d}u_{d,d} \\
		\vdots & \ddots & \vdots \\
		u_{1,d}u_{d,d} & \dots & u_{d,d}u_{d,d}
		\end{pmatrix}
		\\
		&=
		\frac{1}{\lambda_1}u_1u_1^{T} + \dots + \frac{1}{\lambda_d}u_du_d^{T} \\
		&= \sum_{i=1}^{d} \frac{1}{\lambda_i}u_iu_i^T
\end{align}

\exercise
$L = \mathbb{R}^{nxn}$ and is invertible and $Y = LX$ with $X\sim \mathcal{N}(\mu_X,\Sigma_X)$
then $X = L^{-1}Y$. So
\begin{align}
	p_Y(Y) = p_X(X) |det(\frac{\partial x}{\partial y})| = p_X(X) |det(J_{Y \rightarrow X})| = p_X(L^{-1}Y)|det(J_{Y\rightarrow X})|
\end{align}
with
\begin{align}
	J_{Y\rightarrow X} = \frac{\partial x}{\partial y} = \frac{\partial L^{-1}Y}{\partial Y} = L^{-1}
\end{align}

Then
\begin{align}
	p_y(Y) &= p_x(L^{-1}Y)|det(L^{-1}) \\
	&= p_x(L^{-1}Y) \frac{1}{|det(L)|} \\
	&= \frac{1}{\sqrt{(2\pi)^d|det(\Sigma_X|)}}exp(-\frac{1}{2}(L^{-1}Y-\mu_X)^T\Sigma_X^{-1}(L^{-1}Y-\mu_X)) \frac{1}{|det(L)|} \\
	&= \frac{1}{\sqrt{(2\pi)^d|det(\Sigma_X|)}|det(L)|}exp(-\frac{1}{2}(L^{-1}Y-\mu_X)^T\Sigma_X^{-1}(L^{-1}Y-\mu_X)) \\
	&=
	\frac{1}{\sqrt{(2\pi)^d|det(\Sigma_X)||det(L)|^2}}exp(-\frac{1}{2}(L^{-1}Y-\mu_X)^T\Sigma_X^{-1}(L^{-1}Y-\mu_X)) \\
	&=
	\frac{1}{\sqrt{(2\pi)^d|det(\Sigma_X)||det(LL^T)|}}exp(-\frac{1}{2}(L^{-1}Y-\mu_X)^T\Sigma_X^{-1}(L^{-1}Y-\mu_X)) \\
	&=
	\frac{1}{\sqrt{(2\pi)^d|det(L\Sigma_XL^T)|}}exp(-\frac{1}{2}(L^{-1}Y-\mu_X)^T\Sigma_X^{-1}(L^{-1}Y-\mu_X)) \\
	&=
	\frac{1}{\sqrt{(2\pi)^d|det(L\Sigma_XL^T)|}}exp(-\frac{1}{2}(Y-L\mu_X)^T\Sigma_X^{-1}(Y-L\mu_X) \\
	&=
	\frac{1}{\sqrt{(2\pi)^d|det(L\Sigma_XL^T)|}}exp(-\frac{1}{2}L^{-1}(Y-L\mu_X)^T\Sigma_X^{-1}L^{-1}(Y-L\mu_X) \\
	&=
	\frac{1}{\sqrt{(2\pi)^d|det(L\Sigma_XL^T)|}}exp(-\frac{1}{2}(Y-L\mu_X)^TL^{-T}\Sigma_X^{-1}L^{-1}(Y-L\mu_X) \\
	&=
	\frac{1}{\sqrt{(2\pi)^d|det(L\Sigma_XL^T)|}}exp(-\frac{1}{2}(Y-L\mu_X)^T(L\Sigma_XL^T)^{-1}(Y-L\mu_X) \\
	Y &\sim \mathcal{N}(L\mu_X, L\Sigma_XL^T) \\
	Y &\sim \mathcal{N}(\mu_Y,\Sigma_Y)
\end{align}


\exercise
With $p(x) = \mathcal{N}(0, \Sigma_{X})$ and $Y = TX + Z$ with $Z \sim
 \mathcal{N}(0, \Sigma_{Y|X}) $ then
\begin{align}
	\mu_Y &= E[TX+Z] = TE[X] + E[Z] = TE[X] \\
	\Sigma_Y &= T \Sigma_XT^T + \Sigma_Z = T\Sigma_XT^T + \Sigma_{Y|X} \\
					&= T\Sigma_XT^T + \Sigma_Y - \Sigma_{Y,X}\Sigma_{X}^{-1}\Sigma_{X,Y}
\end{align}
This means for T it must hold that
\begin{align}
	T\Sigma_XT^T = \Sigma_{Y,X}\Sigma_{X}^{-1}\Sigma_{X,Y}
\end{align}

\exercise
HW4


\end{document}